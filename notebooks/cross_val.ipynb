{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation on our dataset using Baseline and RNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Data Retrieval\n",
    "from power.ml_ops.data import clean_pv_data, get_pv_data\n",
    "\n",
    "# System\n",
    "import os\n",
    "\n",
    "# Manipulating temporal data and check the types of variables\n",
    "from typing import Dict, List, Tuple, Sequence\n",
    "\n",
    "# tensforflow\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import our clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data loaded\n",
      "# data cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   power\n",
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_raw_data = get_pv_data()\n",
    "pv_df = clean_pv_data(pv_raw_data)\n",
    "pv_df.rename(columns={'electricity': 'power'}, inplace=True)\n",
    "pv_df = pv_df[['power']]\n",
    "pv_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating FOLDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(\n",
    "    df: pd.DataFrame,\n",
    "    fold_length: int,\n",
    "    fold_stride: int) -> List[pd.DataFrame]:\n",
    "    '''\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "\n",
    "    Returns a list of folds, each as a DataFrame\n",
    "    '''\n",
    "    folds = []\n",
    "    for idx in range(0, len(df), fold_stride):\n",
    "        if (idx + fold_length) > len(df):\n",
    "            break\n",
    "        fold = df.iloc[idx:idx + fold_length, :]  # select from row idx til last row of the fold (6 years), all the columns\n",
    "        folds.append(fold)                        # append the 6 year fold to folds\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fold:pd.DataFrame,\n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int) -> Tuple[pd.DataFrame]:\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe (fold_train, fold_test)\n",
    "    from which one can sample (X,y) sequences.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))\n",
    "    '''\n",
    "    # TRAIN SET\n",
    "    # ======================\n",
    "    last_train_idx = round(train_test_ratio * len(fold))    # 83% of the fold for train\n",
    "    fold_train = fold.iloc[0:last_train_idx, :]             # 1st until last row of train set, all columns\n",
    "\n",
    "    # TEST SET\n",
    "    # ======================\n",
    "    first_test_idx = last_train_idx - input_length          # last row of train set - 2 weeks --> test set starts 2 weeks\n",
    "                                                            # before train set ends --> overlap (not a problem with X)\n",
    "    fold_test = fold.iloc[first_test_idx:, :]               # 1st until last row of test set, all columns\n",
    "\n",
    "    return (fold_train, fold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sequences randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a random sequence and then we generate the whole number of sequences of our choice. This function will return two sets of 3D numpy arrays for our inputs and outputs of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xi_yi(\n",
    "    fold:pd.DataFrame,\n",
    "    input_length:int,       # 48\n",
    "    output_length:int):     # 24\n",
    "    '''\n",
    "    - given a fold, it returns one sequence (X_i, y_i)\n",
    "    - with the starting point of the sequence being chosen at random\n",
    "    '''\n",
    "    first_possible_start = 0                                                    # the +1 accounts for the index, that is exclusive.\n",
    "    last_possible_start = len(fold) - (input_length + output_length) + 1        # It can start as long as there are still\n",
    "                                                                                # 48 + 1 days after the 1st day.\n",
    "    random_start = np.random.randint(first_possible_start, last_possible_start) # np.random to pick a day inside the possible interval.\n",
    "\n",
    "    X_i = fold.iloc[random_start:random_start+input_length]\n",
    "    y_i = fold.iloc[random_start+input_length:\n",
    "                  random_start+input_length+output_length][[TARGET]]            # creates a pd.DataFrame for the target y\n",
    "\n",
    "    return (X_i, y_i)\n",
    "\n",
    "def get_X_y(\n",
    "    fold:pd.DataFrame,\n",
    "    number_of_sequences:int,\n",
    "    input_length:int,\n",
    "    output_length:int):\n",
    "\n",
    "    X, y = [], []                                                 # lists for the sequences for X and y\n",
    "\n",
    "    for i in range(number_of_sequences):\n",
    "        (Xi, yi) = get_Xi_yi(fold, input_length, output_length)   # calls the previous function to generate sequences X + y\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_baseline():\n",
    "\n",
    "    model = models.Sequential()\n",
    "    # a layer to take the last value of the sequence and output it\n",
    "    model.add(layers.Lambda(lambda x: x[:,-25:-1,0,None]))                      # all sequences, last day, 1 feature (pv_power)\n",
    "\n",
    "\n",
    "    adam = optimizers.Adam(learning_rate=0.02)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train, n_unit=24, learning_rate=0.02):\n",
    "\n",
    "\n",
    "    # 1 - RNN architecture\n",
    "    # ======================\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ## 1.1 - Recurrent Layer\n",
    "    model.add(layers.LSTM(n_unit,\n",
    "                          activation='tanh',\n",
    "                          return_sequences = False,\n",
    "                          input_shape=(X_train.shape[1],X_train.shape[2])\n",
    "                          ))\n",
    "    ## 1.2 - Predictive Dense Layers\n",
    "    output_length = y_train.shape[1]\n",
    "    model.add(layers.Dense(output_length, activation='linear'))\n",
    "\n",
    "    # 2 - Compiler\n",
    "    # ======================\n",
    "    adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters\n",
    "\n",
    "TARGET = 'power'\n",
    "fold_length = 52560             # 6 years\n",
    "fold_stride = 52560             # 6 years\n",
    "train_test_ratio = 0.83         # 5 yrs/6 yrs\n",
    "input_length = 48               # number of obsevations per one sequence\n",
    "output_length = 24              # Day-ahead predictions\n",
    "n_seq_train = 250               # number_of_sequences_train\n",
    "n_seq_test = 50                 # number_of_sequences_test\n",
    "n_unit = 24                     # number of hidden units\n",
    "learning_rate = 0.02\n",
    "patience = 5\n",
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_baseline_and_lstm():\n",
    "\n",
    "    list_of_mae_baseline_model = []\n",
    "    list_of_mae_recurrent_model = []\n",
    "\n",
    "    # 0 - Creating folds\n",
    "    # =========================================\n",
    "    folds = get_folds(pv_df, fold_length, fold_stride)  # function we coded to get the folds\n",
    "\n",
    "    for fold_id, fold in enumerate(folds):\n",
    "\n",
    "        # 1 - Train/Test split the current fold\n",
    "        # =========================================\n",
    "        (fold_train, fold_test) = train_test_split(fold, train_test_ratio, input_length) # function we coded to split train/test\n",
    "\n",
    "        X_train, y_train = get_X_y(fold_train, n_seq_train, input_length, output_length)\n",
    "        X_test, y_test = get_X_y(fold_test, n_seq_test, input_length, output_length)\n",
    "\n",
    "        # 2 - Modelling\n",
    "        # =========================================\n",
    "\n",
    "        ##### Baseline Model\n",
    "        baseline_model = init_baseline()\n",
    "        mae_baseline = baseline_model.evaluate(X_test, y_test, verbose=0)[1]   # evaluating baseline model (metric)\n",
    "        list_of_mae_baseline_model.append(mae_baseline)\n",
    "        print(\"-\"*50)\n",
    "        print(f\"MAE baseline fold n°{fold_id} = {round(mae_baseline, 2)}\")\n",
    "\n",
    "        ##### LSTM Model\n",
    "        model = init_model(X_train, y_train, n_unit, learning_rate)\n",
    "        es = EarlyStopping(monitor = \"val_mae\",\n",
    "                           mode = \"min\",\n",
    "                           patience = patience,\n",
    "                           restore_best_weights = True)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_split = 0.3,\n",
    "                            shuffle = False,\n",
    "                            batch_size = batch_size,\n",
    "                            epochs = epochs,\n",
    "                            callbacks = [es],\n",
    "                            verbose = 0)\n",
    "        res = model.evaluate(X_test, y_test, verbose=0)    # evaluating LSTM (metric)\n",
    "        mae_lstm = res[1]\n",
    "        list_of_mae_recurrent_model.append(mae_lstm)\n",
    "        print(f\"MAE LSTM fold n°{fold_id} = {round(mae_lstm, 2)}\")\n",
    "\n",
    "        ##### Comparison LSTM vs Baseline for the current fold\n",
    "        print(f\"improvement over baseline: {round((1 - (mae_lstm/mae_baseline))*100,2)} % \\n\")\n",
    "\n",
    "    return list_of_mae_baseline_model, list_of_mae_recurrent_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "MAE baseline fold n°0 = 0.07\n",
      "MAE LSTM fold n°0 = 0.07\n",
      "improvement over baseline: 8.0 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°1 = 0.07\n",
      "MAE LSTM fold n°1 = 0.07\n",
      "improvement over baseline: 6.71 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°2 = 0.07\n",
      "MAE LSTM fold n°2 = 0.07\n",
      "improvement over baseline: -3.89 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°3 = 0.06\n",
      "MAE LSTM fold n°3 = 0.06\n",
      "improvement over baseline: -0.23 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°4 = 0.07\n",
      "MAE LSTM fold n°4 = 0.06\n",
      "improvement over baseline: 16.95 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°5 = 0.07\n",
      "MAE LSTM fold n°5 = 0.06\n",
      "improvement over baseline: 3.34 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°6 = 0.07\n",
      "MAE LSTM fold n°6 = 0.07\n",
      "improvement over baseline: 5.96 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mae_baselines, mae_lstms = cross_validate_baseline_and_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average percentage improvement over baseline = 5.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"average percentage improvement over baseline = {round(np.mean(1 - (np.array(mae_lstms)/np.array(mae_baselines))),2)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
